{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis Using Simple RNN\n",
        "\n",
        "__Objective:__ Build a sentiment analysis model to classify text as positive or negative using RNN.\n",
        "\n",
        "__Data:__ Use a publicly available dataset, such as the IMDB movie reviews dataset.\n",
        "\n",
        "__Technology:__ Python, TensorFlow, and Keras for modeling."
      ],
      "metadata": {
        "id": "I3Xfk1aauUNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries and Modules"
      ],
      "metadata": {
        "id": "dktlqdCPvRhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "metadata": {
        "id": "Yg6QLh8yuusx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Model Parameters\n",
        "This code sets parameters for text processing, specifying the maximum number of words to be considered as features (max_features), the maximum length of texts after which they will be cut (maxlen), and the batch size for processing (batch_size)."
      ],
      "metadata": {
        "id": "-EsYtswXvUkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "maxlen = 500          # Cutting texts after this number of words\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "j58pgbeEuuih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Dataset\n",
        "This code loads the IMDb dataset, with a restriction that only the top max_features most frequent words are included. It retrieves training data (input_train, y_train) and testing data (input_test, y_test) for use in model training and evaluation."
      ],
      "metadata": {
        "id": "6Nn-GBPuvX01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data\n",
        "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)"
      ],
      "metadata": {
        "id": "mFCf3EteuuXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data: Sequence Padding\n",
        "This code pads the sequences in input_train and input_test to a uniform length specified by maxlen to ensure consistent input size for model training and testing."
      ],
      "metadata": {
        "id": "OdAuup8Jva67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding sequences for uniform input size\n",
        "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
        "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "IVAh-SSouuNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the RNN Model\n",
        "This code constructs a recurrent neural network (RNN) model using Keras. It starts with an embedding layer to convert word indices to dense vectors of size 32, adds a simple RNN layer with 32 units, and includes a dense output layer with a sigmoid activation function for binary classification (e.g., positive vs. negative sentiment)."
      ],
      "metadata": {
        "id": "bTQYxjGQveGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(SimpleRNN(32))  # 32 units in the RNN layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification (positive/negative)"
      ],
      "metadata": {
        "id": "yPcNS1x-uuBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling the Model\n",
        "\n",
        "This code compiles the RNN model, setting 'rmsprop' as the optimizer, using 'binary_crossentropy' as the loss function, and tracking accuracy ('acc') as the metric for evaluation."
      ],
      "metadata": {
        "id": "BNUGv7qfvh1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "6kCTZx8mu38B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Displaying Model Summary"
      ],
      "metadata": {
        "id": "Laq1N9XvvlUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-thUlB_Hu3xV",
        "outputId": "6b3160ca-341f-4fea-d281-b18d543a4e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 32)          320000    \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322113 (1.23 MB)\n",
            "Trainable params: 322113 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "\n",
        "This code trains the RNN model on the training data (input_train and y_train), for 10 epochs, with a specified batch size, and uses 20% of the data as a validation set to evaluate the model's performance during training."
      ],
      "metadata": {
        "id": "7A0VKqQnvoJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = model.fit(input_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCFGefkbu3l5",
        "outputId": "5ab59367-6217-49da-806c-ae361db84b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.5275 - acc: 0.7283 - val_loss: 0.4414 - val_acc: 0.8098\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.3428 - acc: 0.8594 - val_loss: 0.3236 - val_acc: 0.8778\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.2784 - acc: 0.8931 - val_loss: 0.3143 - val_acc: 0.8714\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.2381 - acc: 0.9068 - val_loss: 0.3493 - val_acc: 0.8474\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 81s 130ms/step - loss: 0.2037 - acc: 0.9243 - val_loss: 0.5310 - val_acc: 0.8186\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.1742 - acc: 0.9352 - val_loss: 0.3911 - val_acc: 0.8636\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.1457 - acc: 0.9463 - val_loss: 0.4021 - val_acc: 0.8592\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 81s 130ms/step - loss: 0.1228 - acc: 0.9552 - val_loss: 0.4592 - val_acc: 0.8458\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 80s 128ms/step - loss: 0.1015 - acc: 0.9644 - val_loss: 0.5500 - val_acc: 0.8400\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 80s 128ms/step - loss: 0.0810 - acc: 0.9716 - val_loss: 0.6146 - val_acc: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model\n",
        "This code evaluates the trained RNN model on the test dataset (input_test and y_test), computing the test loss and accuracy. It then prints the test accuracy."
      ],
      "metadata": {
        "id": "TLQxTK0evrAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "test_loss, test_acc = model.evaluate(input_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoWbhHJFu882",
        "outputId": "8c0d3f9f-5c81-4ba6-cfa9-4fa2dde8eecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 24s 30ms/step - loss: 0.6043 - acc: 0.7914\n",
            "Test accuracy: 0.7914400100708008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Encoding\n",
        "This code begins by importing necessary components from the TensorFlow Keras library for handling the IMDb dataset and sequence padding. It then loads the IMDb word index dictionary which maps words to integers.\n",
        "\n",
        "The function encode_text is defined to encode a given text into an integer sequence. It processes the text into tokens, converts each token to its corresponding integer using the word_index (defaulting to 0 for unknown words), and then pads this sequence to ensure that all input sequences have the same length (maxlen), which is crucial for consistent input size in model processing."
      ],
      "metadata": {
        "id": "w9N2S-TYvt0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Loading the word index dictionary\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "    # Encoding text to integer sequence using the same word index\n",
        "    tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n",
        "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "    return sequence.pad_sequences([tokens], maxlen=maxlen)  # Using the same maxlen as during training"
      ],
      "metadata": {
        "id": "3_jyO0u5hK_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Sentiment Prediction Function\n",
        "This function predict_sentiment takes a text input, encodes and pads it using the encode_text function to be compatible with the trained RNN model, then predicts the sentiment using the model. The output is interpreted as \"Positive\" if the predicted sigmoid probability is greater than 0.5, otherwise it is \"Negative\"."
      ],
      "metadata": {
        "id": "gwvK-cntv8NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    # Encoding and padding the text to create a compatible input\n",
        "    encoded_text = encode_text(text)\n",
        "\n",
        "    # Prediction\n",
        "    prediction = model.predict(encoded_text)[0][0]  # Output is a sigmoid probability\n",
        "\n",
        "    # Interpreting the result\n",
        "    if prediction > 0.5:\n",
        "        return \"Positive\"\n",
        "    else:\n",
        "        return \"Negative\""
      ],
      "metadata": {
        "id": "tZz_xABZhOUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Sentiment Predictions on Sample Texts\n",
        "This code sets up a list of sample text reviews about movies and iterates over them. For each review, it prints the review text and uses the predict_sentiment function to predict and display the sentiment as either \"Positive\" or \"Negative\"."
      ],
      "metadata": {
        "id": "m09oZ2q_v_NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Samples to test\n",
        "sample_texts = [\n",
        "    \"This was a good movie.\",\n",
        "    \"This movie was an excellent portrayal of a very important story.\"\n",
        "]\n",
        "\n",
        "for text in sample_texts:\n",
        "    print(f'Review: \"{text}\" - Sentiment: {predict_sentiment(text)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH07YgjihP90",
        "outputId": "1df31068-892b-4a8a-edd1-2191401fbad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "Review: \"This was a good movie.\" - Sentiment: Positive\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Review: \"This movie was an excellent portrayal of a very important story.\" - Sentiment: Positive\n"
          ]
        }
      ]
    }
  ]
}